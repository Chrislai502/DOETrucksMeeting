{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "543c5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from pandasql import sqldf\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "import os\n",
    "\n",
    "# Shutil is a recursive tool to delete file paths\n",
    "# Note: Only needed if you plan to overwrite existing filepaths\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c1cd2a",
   "metadata": {},
   "source": [
    "## Node Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "342e97f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Node</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-89.02</td>\n",
       "      <td>41.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-88.36</td>\n",
       "      <td>41.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-88.34</td>\n",
       "      <td>42.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-88.34</td>\n",
       "      <td>42.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-88.32</td>\n",
       "      <td>42.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>80</td>\n",
       "      <td>-83.56</td>\n",
       "      <td>42.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>81</td>\n",
       "      <td>-83.54</td>\n",
       "      <td>41.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>-83.38</td>\n",
       "      <td>42.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>83</td>\n",
       "      <td>-83.36</td>\n",
       "      <td>42.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>84</td>\n",
       "      <td>-82.76</td>\n",
       "      <td>41.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Node    Lon    Lat\n",
       "0      1 -89.02  41.84\n",
       "1      2 -88.36  41.80\n",
       "2      3 -88.34  42.08\n",
       "3      4 -88.34  42.10\n",
       "4      5 -88.32  42.02\n",
       "..   ...    ...    ...\n",
       "79    80 -83.56  42.24\n",
       "80    81 -83.54  41.58\n",
       "81    82 -83.38  42.14\n",
       "82    83 -83.36  42.38\n",
       "83    84 -82.76  41.40\n",
       "\n",
       "[84 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_list = pd.read_csv(os.path.join(os.path.join(os.getcwd(), \"reso0.02\"), 'Node_list_reso0.02_sort.csv'),index_col=0)\n",
    "match_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c37d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the Trucks Data from Cummins Datasheet\n",
    "dataSourcePath = 'given_sources//Batch_Div27_2021_03_months_Class_8_Results_metrics.xlsx'\n",
    "df1 = pd.read_excel(dataSourcePath, index_col=None, usecols=['Vehicle Model-none',\\\n",
    "                      'Battery Energy Consumption per Mile-kWh/mi',\\\n",
    "                      'Fuel Consumption per 100 km-Diesel Equiv. l/100km',\\\n",
    "                      'Initial SOC-%',\\\n",
    "                      'Tire Crr-none',\\\n",
    "                      'Vehicle Static Mass-lbm',\\\n",
    "                      'Cycle Name-none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a2ef100",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mint\u001b[39m(i), \u001b[38;5;28mint\u001b[39m(j))\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m---> 44\u001b[0m df2 \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabelling...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCycle Name-none\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(checking_par)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "# Ruiting Checking method\n",
    "# Logarithmic histogram plots\n",
    "from cmath import nan\n",
    "\n",
    "\n",
    "def checking_par(x):\n",
    "    a = x.replace('p', '.')\n",
    "    a = a.split('_')[1:5]\n",
    "    a = [j for j in a]\n",
    "    return (float(a[0]), float(a[1]), float(a[2]), float(a[3]))\n",
    "\n",
    "def checking_rest(a):\n",
    "    start_node_matched = False\n",
    "    end_node_matched = False\n",
    "    thres = 0.02\n",
    "    \n",
    "    a = [float(x) for x in a]\n",
    "    \n",
    "    lon_lst = match_list['Lon'].values\n",
    "    for idx, lat in enumerate(match_list['Lat'].values):\n",
    "        lon = lon_lst[idx]\n",
    "\n",
    "        # Calculate the distance between node in data and nodelist\n",
    "        # NEED MODIFICATION\n",
    "        '''\n",
    "        i_dist = np.sqrt((lat-a[0])**2 + (lon - a[1])**2) \n",
    "        j_dist = np.sqrt((lat-a[2])**2 + (lon - a[3])**2)\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        if ((i_dist <= thres) and not start_node_matched):\n",
    "            i = match_list['Node'].iloc[[idx]].values[0]\n",
    "            start_node_matched = True\n",
    "        \n",
    "        if ((j_dist <= thres) and not end_node_matched):\n",
    "            j = match_list['Node'].iloc[[idx]].values[0]\n",
    "            end_node_matched = True\n",
    "        \n",
    "        # If both nodes are already matched, exit\n",
    "        if(start_node_matched and end_node_matched):\n",
    "            return (int(i), int(j))\n",
    "        \n",
    "    return np.nan\n",
    "\n",
    "df2 = df1.copy()\n",
    "print(\"Labelling...\")\n",
    "df2['temp'] = df2['Cycle Name-none'].apply(checking_par)\n",
    "df2[['S_lat','S_lon','E_lat','E_lon']] = pd.DataFrame(df2.temp.tolist(), index= df2.index).div(2).round(2).multiply(2)\n",
    "df3 = df2.merge(match_list,how='left',left_on=['S_lat','S_lon'],right_on=['Lat','Lon']).merge(match_list,how='left',left_on=['E_lat','E_lon'],right_on=['Lat','Lon'])\n",
    "\n",
    "df2['(i, j)'] = df2['temp'].apply(checking_rest)\n",
    "# a = pd.DataFrame(df2['(i, j)'].tolist(), index=df2.index)\n",
    "temp = df2.columns.get_loc('Cycle Name-none')\n",
    "\n",
    "df2.insert(temp + 1, 'i', 0)\n",
    "df2.insert(temp + 2, 'j', 0)\n",
    "\n",
    "\n",
    "print(\"Done Labelling\")\n",
    "df2['Fuel Consumption per km-Diesel Equiv. l/km']= df2['Fuel Consumption per 100 km-Diesel Equiv. l/100km'] / 100\n",
    "df2['Battery Energy Consumption per km-kWh/km']= df2['Battery Energy Consumption per Mile-kWh/mi']/1.60934\n",
    "df2['Vehicle Static Mass-kg']= df2['Vehicle Static Mass-lbm']*0.453592"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef304ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507ed828",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['i'] = df3['Node_x']#.astype(int)\n",
    "df2['j'] = df3['Node_y']#.astype(int)\n",
    "for ind,row in df2.iterrows():\n",
    "    if pd.isnull(row.i):\n",
    "        df2.i[ind] = row['(i, j)'][0]\n",
    "    if pd.isnull(row.j):\n",
    "        df2.j[ind]  = row['(i, j)'][1]\n",
    "\n",
    "print(\"Dropping cols\")\n",
    "df2['i'] = df2['i'].astype(int)\n",
    "df2['j'] = df2['j'].astype(int)\n",
    "df2.to_csv('energy_w_n.csv')\n",
    "# df2.drop(['temp','(i, j)', 'Fuel Consumption per 100 km-Diesel Equiv. l/100km', \\\n",
    "#           'Battery Energy Consumption per Mile-kWh/mi', \\\n",
    "#           'Vehicle Static Mass-lbm','S_lat','S_lon','E_lat','E_lon'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1b7562",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(np.arange(1, 85)) - set(df2.i.unique()).union(set(df2.j.unique()))) # Should be empty\n",
    "df2.head(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52078dc",
   "metadata": {},
   "source": [
    "# Performing OLS\n",
    "Note:  -1 is a dummy value (for self-loops and array padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982bb37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for csv files index and column labels\n",
    "# df = df_conv\n",
    "# df = df_fchev\n",
    "# df = df_mild\n",
    "# df = df_bev\n",
    "# df = df_erev\n",
    "df = df2.copy()\n",
    "\n",
    "saveFolderName = \"OLS_Data\"\n",
    "parent_dir = os.getcwd()\n",
    "savePath = os.path.join(parent_dir, saveFolderName)\n",
    "\n",
    "# If the folder already exists, remove the folder\n",
    "if os.path.exists(savePath):\n",
    "    shutil.rmtree(savePath)\n",
    "\n",
    "vehicleTypes = pd.Series(df['Vehicle Model-none'].values).unique()\n",
    "tireTypes = pd.Series(df['Tire Crr-none'].values).unique()\n",
    "\n",
    "numNodes = len(set(df.i.unique()).union(set(df.j.unique())))\n",
    "print(\"Number of detected Nodes: \", numNodes)\n",
    "cols = [\"i_\" + str(i) for i in range(1, numNodes+1)]\n",
    "rows = [\"j_\" + str(i) for i in range(1, numNodes+1)]\n",
    "\n",
    "# Loop for Vehicle Types (k)\n",
    "for tires in tireTypes:\n",
    "    workFrame = df[df[\"Tire Crr-none\"] == tires]\n",
    "    tempPath1 = os.path.join(savePath, \"Tire_cir_\" + str(tires)) \n",
    "    os.makedirs(tempPath1) # Creating the directories\n",
    "\n",
    "    for v in vehicleTypes:\n",
    "        workFrame = df[df[\"Vehicle Model-none\"] == v]\n",
    "        need_elec = False\n",
    "        need_fuel = False\n",
    "        \n",
    "        # Figuring out what type of vehicle is currently being processed and filtering out values that are not needed\n",
    "        \n",
    "        # Dropping Unneeded columns at this point\n",
    "        workFrame = df.drop(['Tire Crr-none', 'Cycle Name-none', 'Vehicle Model-none'],axis= 1)\n",
    "        \n",
    "        if   v.find('conv') != -1 :\n",
    "            v_type = 'C'\n",
    "            need_fuel = True\n",
    "        elif v.find('erev') != -1:\n",
    "            v_type = 'E'\n",
    "            need_elec = True\n",
    "            need_fuel = True\n",
    "        elif v.find('fchev') != -1:\n",
    "            v_type = 'F'\n",
    "            need_fuel = True\n",
    "        elif v.find('mild') != -1:\n",
    "            v_type = 'M'\n",
    "            need_fuel = True\n",
    "        elif v.find('bev') != -1:\n",
    "            v_type = 'B'\n",
    "            need_elec = True\n",
    "        else:\n",
    "            print('ERROR! Could not find vehicle Type')\n",
    "            break\n",
    "            \n",
    "        print('\\nFor Vehiecle: ', v, ', Tire: Cir_', tires)\n",
    "        print('Detected type: ', v_type)\n",
    "        \n",
    "        \n",
    "        # Create both files anyway, and then decide later when saving\n",
    "        newFrame_elec = pd.DataFrame(columns = cols, index = rows)\n",
    "        newFrame_fuel = pd.DataFrame(columns = cols, index = rows)\n",
    "        \n",
    "        # Iterate over node values i, j, and assign constants a, b, into \"newFrame\"\n",
    "        for i in range(1, numNodes + 1):\n",
    "            for j in range(1, numNodes + 1):\n",
    "\n",
    "                data = workFrame.loc[((workFrame['i'] == i) & (workFrame['j'] == j))]\n",
    "\n",
    "                # edge case if i = j or data Doesn't exist\n",
    "                if i == j :\n",
    "                    newFrame_elec.iat[i-1, j-1] = -1\n",
    "                    newFrame_fuel.iat[i-1, j-1] = -1\n",
    "                    continue\n",
    "\n",
    "                elif data.size == 0:\n",
    "                    newFrame_elec.iat[i-1, j-1] = 0 #(0.0, 0.0, 0.0)\n",
    "                    newFrame_fuel.iat[i-1, j-1] = 0 #(0.0, 0.0, 0.0)\n",
    "                    continue\n",
    "                \n",
    "                # Doing linear regression here\n",
    "                if   v_type == 'C' : # type conv\n",
    "                    Y_f = data['Fuel Consumption per km-Diesel Equiv. l/km']\n",
    "                    X_f = data['Vehicle Static Mass-kg'].to_frame()\n",
    "                elif v_type == 'B': # type bev\n",
    "                    Y_e = data['Battery Energy Consumption per km-kWh/km']\n",
    "                    X_e = data['Vehicle Static Mass-kg'].to_frame()\n",
    "                elif v_type == 'E': # type erev\n",
    "                    Y_e = data['Battery Energy Consumption per km-kWh/km']\n",
    "                    Y_f = data['Fuel Consumption per km-Diesel Equiv. l/km']\n",
    "                    X_f = data[['Initial SOC-%', 'Vehicle Static Mass-kg']]\n",
    "                    X_e = data[['Initial SOC-%', 'Vehicle Static Mass-kg']]\n",
    "                elif v_type == 'F': # type fchev\n",
    "                    Y_f = data['Fuel Consumption per km-Diesel Equiv. l/km']\n",
    "                    X_f = data['Vehicle Static Mass-kg'].to_frame()\n",
    "                elif v_type == 'M': # type mild\n",
    "                    Y_f = data['Fuel Consumption per km-Diesel Equiv. l/km']\n",
    "                    X_f = data['Vehicle Static Mass-kg'].to_frame()\n",
    "    \n",
    "                # Select if 2 linear regressions is needed\n",
    "                # creating train and test sets\n",
    "                if (need_fuel):\n",
    "                    X_train, _, y_train, _ = train_test_split(X_f, Y_f, test_size=0.000001)\n",
    "                    LR = LinearRegression()  # create object for the class\n",
    "                    LR.fit(X_train, y_train)  # perform linear regression\n",
    "                    if (len(LR.coef_) == 2): # need to check if it works\n",
    "                        newFrame_fuel.iat[j - 1, i - 1] = (LR.coef_.item(0), LR.coef_.item(1), LR.intercept_.item(0)) \n",
    "                    else:\n",
    "                        newFrame_fuel.iat[j - 1, i - 1] = (0.0, LR.coef_.item(0), LR.intercept_.item(0))\n",
    "                if (need_elec):\n",
    "                    X_train, _, y_train, _ = train_test_split(X_e, Y_e, test_size=0.000001)\n",
    "                    LR = LinearRegression()  # create object for the class\n",
    "                    LR.fit(X_train, y_train)  # perform linear regression\n",
    "                    if (len(LR.coef_) == 2): # need to check if it works\n",
    "                        newFrame_elec.iat[j - 1, i - 1] = (LR.coef_.item(0), LR.coef_.item(1), LR.intercept_.item(0))\n",
    "                    else:\n",
    "                        newFrame_elec.iat[j - 1, i - 1] = (0.0, LR.coef_.item(0), LR.intercept_.item(0))\n",
    "\n",
    "        # Create the filePath\n",
    "#         newFrame_fuel.fillna(0)\n",
    "#         newFrame_elec.fillna(0)\n",
    "        if (need_fuel):\n",
    "            tempPath2 = os.path.join(tempPath1, \"Fuel_\" + v + \".csv\")\n",
    "            tempPath3 = os.path.join(tempPath1, \"Fuel_\" + v + \".pkl\")\n",
    "            newFrame_fuel.to_csv(tempPath2)\n",
    "            newFrame_fuel.to_pickle(tempPath3)\n",
    "        if (need_elec):\n",
    "            tempPath2 = os.path.join(tempPath1, \"Elec_\" + v + \".csv\")\n",
    "            tempPath3 = os.path.join(tempPath1, \"Elec_\" + v + \".pkl\")\n",
    "            newFrame_elec.to_csv(tempPath2)\n",
    "            newFrame_elec.to_pickle(tempPath3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736f5e0b",
   "metadata": {},
   "source": [
    "\n",
    "# Function: readData\n",
    " ### Reads the source folder generated and returns a, b, c as dictionaries.\n",
    " \n",
    "### Note:  -1 is a dummy value (for self-loops and array padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9785cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTDATED \n",
    "# =======================================================\n",
    "# FUNCTION: Reader of pickle files for (a, b) coefficients\n",
    "#   a, b = readDataCSV(\"<Folder Name>\")\n",
    "#\n",
    "# Arguments:\n",
    "#   saveFolderName    (str ) the foldername for the stored pickle files. Default :\"OLS_Data\"\n",
    "#\n",
    "# Returns:\n",
    "#   a [ k ][ i ][ j ] (dict) k is the Vehiecle Type, i is the starting node, and j is the end node\n",
    "#   b [ k ][ i ][ j ] (dict) k is the Vehiecle Type, i is the starting node, and j is the end node\n",
    "# \n",
    "#   Notes:\n",
    "#   - i and j are 1 indexed, for convenience. i = 0 or j = 0, holds garbage values.\n",
    "#   - The name of vehicles, k, needs to be exactly the same as the \n",
    "#     column from the datafile used to generate the pickle files.\n",
    "# =======================================================\n",
    "\n",
    "def readDataPKL (saveFolderName = \"OLS_Data\"):\n",
    "    \n",
    "    # Initialize some folderpath\n",
    "    path = os.path.join(os.getcwd(), saveFolderName)\n",
    "    \n",
    "    # If the folder doesn't exist, print error and return\n",
    "    if not os.path.exists(path):\n",
    "        print(\"Error, Source Folder Doesn't exist\")\n",
    "        return \n",
    "    \n",
    "    TireTypes = [i[9:] for i in os.listdir(path)]\n",
    "    \n",
    "    # Get the number of nodes brute forcedly\n",
    "    filePath = os.path.join(path, 'Tire_cir_' + TireTypes[0])\n",
    "    VehiecleSamplePath = [ fi for fi in os.listdir(filePath) if fi.endswith(\".pkl\") ]\n",
    "    filePath = os.path.join(filePath, VehiecleSamplePath[0])\n",
    "    df = pd.read_pickle(filePath)\n",
    "    numNodes = np.shape(df.iloc[:, 0].values)[0]\n",
    "    \n",
    "    # Initializing return dictionary\n",
    "    a = {}\n",
    "    b = {}\n",
    "    c = {}\n",
    "    \n",
    "    fuelType = ['Fuel','Elec']\n",
    "    \n",
    "    for t in TireTypes:\n",
    "        t_path = os.path.join(path, 'Tire_cir_' + t)\n",
    "        a[t] = {}\n",
    "        b[t] = {}\n",
    "        c[t] = {}\n",
    "        VehiecleTypesPath = [ fi for fi in os.listdir(t_path) if fi.endswith(\".pkl\") ]\n",
    "        VehiecleTypes = [i[5:len(i) - 4] for i in VehiecleTypesPath] # change to use split or something else\n",
    "        VehiecleTypes = list(set(VehiecleTypes))# remove duplicates\n",
    "        \n",
    "        for f in fuelType:\n",
    "            a[t][f] = {}\n",
    "            b[t][f] = {}\n",
    "            c[t][f] = {}\n",
    "            for ind, v in enumerate(VehiecleTypes):\n",
    "                filePath = os.path.join(t_path, f + \"_\" + v + \".pkl\")\n",
    "                if not os.path.exists(filePath):\n",
    "                    a[t][f][v] = np.full((numNodes + 1, numNodes + 1), np.nan)\n",
    "                    b[t][f][v] = np.full((numNodes + 1, numNodes + 1), np.nan)\n",
    "                    c[t][f][v] = np.full((numNodes + 1, numNodes + 1), np.nan)\n",
    "                    continue \n",
    "                df = pd.read_pickle(filePath)\n",
    "\n",
    "                # initialize an empty array to store the days\n",
    "                a[t][f][v] = np.full((numNodes + 1, numNodes + 1), -1, dtype = float)\n",
    "                b[t][f][v] = np.full((numNodes + 1, numNodes + 1), -1, dtype = float)\n",
    "                c[t][f][v] = np.full((numNodes + 1, numNodes + 1), -1, dtype = float)\n",
    "\n",
    "                results = df.to_numpy().transpose()\n",
    "                for i, temp in enumerate(results, 1):\n",
    "                    for j, ab in enumerate(temp, 1):\n",
    "                        if type(ab) == tuple:\n",
    "                            a[t][f][v][i][j], b[t][f][v][i][j], c[t][f][v][i][j] = ab[0], ab[1] , ab[2] \n",
    "                        else:\n",
    "                            a[t][f][v][i][j], b[t][f][v][i][j], c[t][f][v][i][j] = np.nan, np.nan, np.nan\n",
    "\n",
    "    return a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e3a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = readDataPKL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbf36e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example lookup\n",
    "t = '0.00427'\n",
    "f = 'Elec' # or 'Fuel'\n",
    "# v = 'class8_conv_2021_daycab_regionalhaul_FU19'\n",
    "# v = 'class8_bev_2021_daycab_regionalhaul_FU19'\n",
    "v = 'class8_bev_2021_low_sleeper_longhaul_FU19'\n",
    "i = 1\n",
    "j = 2\n",
    "\n",
    "a[t][f][v][i][j], b[t][f][v][i][j], c[t][f][v][i][j] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a6ac27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "073db2c05fe2e61e4b0689b91de786d55e908d59f913932575f4ad3a7694549a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
