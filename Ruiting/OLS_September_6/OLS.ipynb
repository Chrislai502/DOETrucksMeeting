{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "543c5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "import os\n",
    "\n",
    "# Shutil is a recursive tool to delete file paths\n",
    "# Note: Only needed if you plan to overwrite existing filepaths\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c1cd2a",
   "metadata": {},
   "source": [
    "## Node Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "342e97f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Node</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41.69</td>\n",
       "      <td>-86.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>41.67</td>\n",
       "      <td>-85.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>41.43</td>\n",
       "      <td>-85.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>40.40</td>\n",
       "      <td>-86.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>40.72</td>\n",
       "      <td>-86.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>42.18</td>\n",
       "      <td>-87.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "      <td>41.72</td>\n",
       "      <td>-85.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>41.62</td>\n",
       "      <td>-88.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>81</td>\n",
       "      <td>42.00</td>\n",
       "      <td>-88.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "      <td>41.43</td>\n",
       "      <td>-87.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Node    Lat    Lon\n",
       "0            0     1  41.69 -86.15\n",
       "1            1     2  41.67 -85.99\n",
       "2            2     3  41.43 -85.27\n",
       "3            3     4  40.40 -86.85\n",
       "4            4     5  40.72 -86.03\n",
       "..         ...   ...    ...    ...\n",
       "77          77    78  42.18 -87.94\n",
       "78          78    79  41.72 -85.81\n",
       "79          79    80  41.62 -88.12\n",
       "80          80    81  42.00 -88.01\n",
       "81          81    82  41.43 -87.78\n",
       "\n",
       "[82 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_list = pd.read_csv(os.getcwd() + '/given_sources/node_list.csv')\n",
    "match_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "364bb170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(match_list.Lat.unique()).union(set(match_list.Lon.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c37d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the Trucks Data from Cummins Datasheet\n",
    "dataSourcePath = os.getcwd() + '/given_sources/Batch_Div27_2021_03_months_Class_8_Results_metrics.xlsx'\n",
    "df1 = pd.read_excel(dataSourcePath, index_col=None, usecols=['Vehicle Model-none',\\\n",
    "                      'Battery Energy Consumption per Mile-kWh/mi',\\\n",
    "                      'Fuel Consumption per 100 km-Diesel Equiv. l/100km',\\\n",
    "                      'Initial SOC-%',\\\n",
    "                      'Tire Crr-none',\\\n",
    "                      'Vehicle Static Mass-lbm',\\\n",
    "                      'Cycle Name-none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b1b3203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Function that compares the cycle name to the node_matching_list to label node indices\n",
    "# Into the original datasheet\n",
    "def checking(x):\n",
    "    \n",
    "    start_node_matched = False\n",
    "    end_node_matched = False\n",
    "    thres = 0.01\n",
    "    \n",
    "    for idx, lat in enumerate(match_list['Lat'].values):\n",
    "        lon = match_list['Lon'].values[idx]\n",
    "\n",
    "        a = x.replace('p', '.')\n",
    "        a = a.split('_')[1:5]\n",
    "        a = [round(float(j), 2) for j in a]\n",
    "\n",
    "        # If start node matched matches\n",
    "        if (((a[0] <= round(lat+thres,2)) and (a[0] >= round(lat-thres, 2))) and ((a[1] <= round(lon+thres, 2)) and (a[1] >= round(lon-thres, 2))) and not start_node_matched):\n",
    "            # get the start, and end node\n",
    "            i = match_list['Node'].iloc[[idx]].values[0]\n",
    "            start_node_matched = True\n",
    "#             print('Start Matched')\n",
    "            \n",
    "            \n",
    "        # If end node matched\n",
    "        elif(((a[2] <= round(lat+thres, 2)) and (a[2] >= round(lat-thres, 2))) and ((a[3] <= round(lon+thres, 2)) and (a[3] >= round(lon-thres, 2))) and not end_node_matched):\n",
    "            j = match_list['Node'].iloc[[idx]].values[0]\n",
    "            end_node_matched = True\n",
    "#             print('End Matched')\n",
    "            \n",
    "        # If both nodes are already matched, exit\n",
    "        if(start_node_matched and end_node_matched):\n",
    "            return (int(i), int(j))\n",
    "        \n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e94fbd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Start Node, End Node) = (18, 38)\n",
      "From Data:  [42.09, -88.34, 42.1, -88.35]\n"
     ]
    }
   ],
   "source": [
    "test_case = 'Edge_39p379_-84p242_41p687_-86p149_Raw_Class_8'\n",
    "# test_case = 'Edge_40p765_-87p112_41p687_-86p149_Raw_Class_8'\n",
    "test_case = 'Edge_41p687_-86p149_42p253_-85p550_Raw_Class_8' # 1, \n",
    "test_case = 'Edge_41p687_-86p149_42p249_-85p543_Raw_Class_8' # 1, \n",
    "test_case = 'Edge_41p687_-86p149_42p903_-85p535_Raw_Class_8' # 1, 21\n",
    "test_case = 'Edge_42p094_-88p345_42p100_-88p347_Raw_Class_8'\n",
    "test_case = 'Edge_42p817_-85p986_42p812_-86p001_Raw_Class_8'\n",
    "test_case = 'Edge_42p094_-88p345_42p100_-88p347_Raw_Class_8'\n",
    "\n",
    "print(\"(Start Node, End Node) =\", checking(test_case))\n",
    "a = test_case.replace('p', '.')\n",
    "a = a.split('_')[1:5]\n",
    "a = [round(float(j), 2) for j in a]\n",
    "print(\"From Data: \", a)\n",
    "\n",
    "test_case = 'Edge_42p094_-88p345_42p100_-88p347_Raw_Class_8'\n",
    "# Node 9, lon, lat: -88.34\t42.1  \n",
    "# Node37, lon, lat: -88.34\t42.08 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a2ef100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the smallest range between 2 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af227438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Copying\n",
      "Labelling...\n",
      "Done Labelling\n",
      "Dropping cols\n",
      "file made!\n"
     ]
    }
   ],
   "source": [
    "# This portion of code mainly runs conversion and relabling\n",
    "df2 = df1.copy()\n",
    "print(\"Done Copying\")\n",
    "print(\"Labelling...\")\n",
    "temp = df2.columns.get_loc('Cycle Name-none')\n",
    "df2['temp'] = df2['Cycle Name-none'].apply(checking)\n",
    "\n",
    "a = pd.DataFrame(df2['temp'].tolist(), index=df2.index)\n",
    "df2.insert(temp + 1, 'i', a[0])\n",
    "df2.insert(temp + 2, 'j', a[1])\n",
    "\n",
    "print(\"Done Labelling\")\n",
    "df2['Fuel Consumption per km-Diesel Equiv. l/km']= df2['Fuel Consumption per 100 km-Diesel Equiv. l/100km'] / 100\n",
    "df2['Battery Energy Consumption per km-kWh/km']= df2['Battery Energy Consumption per Mile-kWh/mi']/1.60934\n",
    "df2['Vehicle Static Mass-kg']= df2['Vehicle Static Mass-lbm']*0.453592\n",
    "print(\"Dropping cols\")\n",
    "df2.drop(['temp', 'Fuel Consumption per 100 km-Diesel Equiv. l/100km', \\\n",
    "          'Battery Energy Consumption per Mile-kWh/mi', \\\n",
    "          'Vehicle Static Mass-lbm'], inplace=True, axis=1)\n",
    "df2.head(n = 10)\n",
    "\n",
    "# Make File \n",
    "print(\"file made!\")\n",
    "df2.to_csv('given_sources/labelled_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52078dc",
   "metadata": {},
   "source": [
    "# Performing OLS\n",
    "Note:  -1 is a dummy value (for self-loops and array padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "982bb37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of detected Nodes:  82\n",
      "\n",
      "For Vehiecle:  class8_conv_2021_low_sleeper_longhaul_FU19 , Tire: Cir_ 0.0061\n",
      "Detected type:  C\n",
      "\n",
      "For Vehiecle:  class8_mild48v_2021_low_sleeper_longhaul_FU19 , Tire: Cir_ 0.0061\n",
      "Detected type:  M\n",
      "\n",
      "For Vehiecle:  class8_erev_2021_low_sleeper_longhaul_FU19 , Tire: Cir_ 0.0061\n",
      "Detected type:  E\n",
      "\n",
      "For Vehiecle:  class8_bev_2021_low_sleeper_longhaul_FU19 , Tire: Cir_ 0.0061\n",
      "Detected type:  B\n",
      "\n",
      "For Vehiecle:  class8_fchev_2021_low_sleeper_longhaul_FU19 , Tire: Cir_ 0.0061\n",
      "Detected type:  F\n",
      "\n",
      "For Vehiecle:  class8_conv_2021_daycab_regionalhaul_FU19 , Tire: Cir_ 0.0061\n",
      "Detected type:  C\n",
      "\n",
      "For Vehiecle:  class8_mild48v_2021_daycab_regionalhaul_FU19 , Tire: Cir_ 0.0061\n",
      "Detected type:  M\n",
      "\n",
      "For Vehiecle:  class8_erev_2021_daycab_regionalhaul_FU19 , Tire: Cir_ 0.0061\n",
      "Detected type:  E\n",
      "\n",
      "For Vehiecle:  class8_bev_2021_daycab_regionalhaul_FU19 , Tire: Cir_ 0.0061\n",
      "Detected type:  B\n",
      "\n",
      "For Vehiecle:  class8_fchev_2021_daycab_regionalhaul_FU19 , Tire: Cir_ 0.0061\n",
      "Detected type:  F\n",
      "\n",
      "For Vehiecle:  class8_conv_2021_low_sleeper_longhaul_FU19 , Tire: Cir_ 0.00427\n",
      "Detected type:  C\n",
      "\n",
      "For Vehiecle:  class8_mild48v_2021_low_sleeper_longhaul_FU19 , Tire: Cir_ 0.00427\n",
      "Detected type:  M\n",
      "\n",
      "For Vehiecle:  class8_erev_2021_low_sleeper_longhaul_FU19 , Tire: Cir_ 0.00427\n",
      "Detected type:  E\n",
      "\n",
      "For Vehiecle:  class8_bev_2021_low_sleeper_longhaul_FU19 , Tire: Cir_ 0.00427\n",
      "Detected type:  B\n",
      "\n",
      "For Vehiecle:  class8_fchev_2021_low_sleeper_longhaul_FU19 , Tire: Cir_ 0.00427\n",
      "Detected type:  F\n",
      "\n",
      "For Vehiecle:  class8_conv_2021_daycab_regionalhaul_FU19 , Tire: Cir_ 0.00427\n",
      "Detected type:  C\n",
      "\n",
      "For Vehiecle:  class8_mild48v_2021_daycab_regionalhaul_FU19 , Tire: Cir_ 0.00427\n",
      "Detected type:  M\n",
      "\n",
      "For Vehiecle:  class8_erev_2021_daycab_regionalhaul_FU19 , Tire: Cir_ 0.00427\n",
      "Detected type:  E\n",
      "\n",
      "For Vehiecle:  class8_bev_2021_daycab_regionalhaul_FU19 , Tire: Cir_ 0.00427\n",
      "Detected type:  B\n",
      "\n",
      "For Vehiecle:  class8_fchev_2021_daycab_regionalhaul_FU19 , Tire: Cir_ 0.00427\n",
      "Detected type:  F\n"
     ]
    }
   ],
   "source": [
    "# Setup for csv files index and column labels\n",
    "# df = df_conv\n",
    "# df = df_fchev\n",
    "# df = df_mild\n",
    "# df = df_bev\n",
    "# df = df_erev\n",
    "df = df2.copy()\n",
    "\n",
    "saveFolderName = \"OLS_Data\"\n",
    "parent_dir = os.getcwd()\n",
    "savePath = os.path.join(parent_dir, saveFolderName)\n",
    "\n",
    "# If the folder already exists, remove the folder\n",
    "if os.path.exists(savePath):\n",
    "    shutil.rmtree(savePath)\n",
    "\n",
    "vehicleTypes = pd.Series(df['Vehicle Model-none'].values).unique()\n",
    "tireTypes = pd.Series(df['Tire Crr-none'].values).unique()\n",
    "\n",
    "numNodes = len(set(df.i.unique()).union(set(df.j.unique())))\n",
    "print(\"Number of detected Nodes: \", numNodes)\n",
    "cols = [\"i_\" + str(i) for i in range(1, numNodes+1)]\n",
    "rows = [\"j_\" + str(i) for i in range(1, numNodes+1)]\n",
    "\n",
    "# Loop for Vehicle Types (k)\n",
    "for tires in tireTypes:\n",
    "    workFrame = df[df[\"Tire Crr-none\"] == tires]\n",
    "    tempPath1 = os.path.join(savePath, \"Tire_cir_\" + str(tires)) \n",
    "    os.makedirs(tempPath1) # Creating the directories\n",
    "\n",
    "    for v in vehicleTypes:\n",
    "        workFrame = df[df[\"Vehicle Model-none\"] == v]\n",
    "        need_elec = False\n",
    "        need_fuel = False\n",
    "        \n",
    "        # Figuring out what type of vehicle is currently being processed and filtering out values that are not needed\n",
    "        \n",
    "        # Dropping Unneeded columns at this point\n",
    "        workFrame = df.drop(['Tire Crr-none', 'Cycle Name-none', 'Vehicle Model-none'],axis= 1)\n",
    "        \n",
    "        if   v.find('conv') != -1 :\n",
    "            v_type = 'C'\n",
    "            need_fuel = True\n",
    "        elif v.find('erev') != -1:\n",
    "            v_type = 'E'\n",
    "            need_elec = True\n",
    "            need_fuel = True\n",
    "        elif v.find('fchev') != -1:\n",
    "            v_type = 'F'\n",
    "            need_fuel = True\n",
    "        elif v.find('mild') != -1:\n",
    "            v_type = 'M'\n",
    "            need_fuel = True\n",
    "        elif v.find('bev') != -1:\n",
    "            v_type = 'B'\n",
    "            need_elec = True\n",
    "        else:\n",
    "            print('ERROR! Could not find vehicle Type')\n",
    "            break\n",
    "            \n",
    "        print('\\nFor Vehiecle: ', v, ', Tire: Cir_', tires)\n",
    "        print('Detected type: ', v_type)\n",
    "        \n",
    "        \n",
    "        # Create both files anyway, and then decide later when saving\n",
    "        newFrame_elec = pd.DataFrame(columns = cols, index = rows)\n",
    "        newFrame_fuel = pd.DataFrame(columns = cols, index = rows)\n",
    "        \n",
    "        # Iterate over node values i, j, and assign constants a, b, into \"newFrame\"\n",
    "        for i in range(1, numNodes + 1):\n",
    "            for j in range(1, numNodes + 1):\n",
    "\n",
    "                data = workFrame.loc[((workFrame['i'] == i) & (workFrame['j'] == j))]\n",
    "\n",
    "                # edge case if i = j or data Doesn't exist\n",
    "                if i == j :\n",
    "                    newFrame_elec.iat[i-1, j-1] = -1\n",
    "                    newFrame_fuel.iat[i-1, j-1] = -1\n",
    "                    continue\n",
    "\n",
    "                elif data.size == 0:\n",
    "                    newFrame_elec.iat[i-1, j-1] = 0 #(0.0, 0.0, 0.0)\n",
    "                    newFrame_fuel.iat[i-1, j-1] = 0 #(0.0, 0.0, 0.0)\n",
    "                    continue\n",
    "                \n",
    "                # Doing linear regression here\n",
    "                if   v_type == 'C' : # type conv\n",
    "                    Y_f = data['Fuel Consumption per km-Diesel Equiv. l/km']\n",
    "                    X_f = data['Vehicle Static Mass-kg'].to_frame()\n",
    "                elif v_type == 'B': # type bev\n",
    "                    Y_e = data['Battery Energy Consumption per km-kWh/km']\n",
    "                    X_e = data['Vehicle Static Mass-kg'].to_frame()\n",
    "                elif v_type == 'E': # type erev\n",
    "                    Y_e = data['Battery Energy Consumption per km-kWh/km']\n",
    "                    Y_f = data['Fuel Consumption per km-Diesel Equiv. l/km']\n",
    "                    X_f = data[['Initial SOC-%', 'Vehicle Static Mass-kg']]\n",
    "                    X_e = data[['Initial SOC-%', 'Vehicle Static Mass-kg']]\n",
    "                elif v_type == 'F': # type fchev\n",
    "                    Y_f = data['Fuel Consumption per km-Diesel Equiv. l/km']\n",
    "                    X_f = data['Vehicle Static Mass-kg'].to_frame()\n",
    "                elif v_type == 'M': # type mild\n",
    "                    Y_f = data['Fuel Consumption per km-Diesel Equiv. l/km']\n",
    "                    X_f = data['Vehicle Static Mass-kg'].to_frame()\n",
    "    \n",
    "                # Select if 2 linear regressions is needed\n",
    "                # creating train and test sets\n",
    "                if (need_fuel):\n",
    "                    X_train, _, y_train, _ = train_test_split(X_f, Y_f, test_size=0.000001)\n",
    "                    LR = LinearRegression()  # create object for the class\n",
    "                    LR.fit(X_train, y_train)  # perform linear regression\n",
    "                    if (len(LR.coef_) == 2): # need to check if it works\n",
    "                        newFrame_fuel.iat[j - 1, i - 1] = (LR.coef_.item(0), LR.coef_.item(1), LR.intercept_.item(0)) \n",
    "                    else:\n",
    "                        newFrame_fuel.iat[j - 1, i - 1] = (0.0, LR.coef_.item(0), LR.intercept_.item(0))\n",
    "                if (need_elec):\n",
    "                    X_train, _, y_train, _ = train_test_split(X_e, Y_e, test_size=0.000001)\n",
    "                    LR = LinearRegression()  # create object for the class\n",
    "                    LR.fit(X_train, y_train)  # perform linear regression\n",
    "                    if (len(LR.coef_) == 2): # need to check if it works\n",
    "                        newFrame_elec.iat[j - 1, i - 1] = (LR.coef_.item(0), LR.coef_.item(1), LR.intercept_.item(0))\n",
    "                    else:\n",
    "                        newFrame_elec.iat[j - 1, i - 1] = (0.0, LR.coef_.item(0), LR.intercept_.item(0))\n",
    "\n",
    "        # Create the filePath\n",
    "#         newFrame_fuel.fillna(0)\n",
    "#         newFrame_elec.fillna(0)\n",
    "        if (need_fuel):\n",
    "            tempPath2 = os.path.join(tempPath1, \"Fuel_\" + v + \".csv\")\n",
    "            tempPath3 = os.path.join(tempPath1, \"Fuel_\" + v + \".pkl\")\n",
    "            newFrame_fuel.to_csv(tempPath2)\n",
    "            newFrame_fuel.to_pickle(tempPath3)\n",
    "        if (need_elec):\n",
    "            tempPath2 = os.path.join(tempPath1, \"Elec_\" + v + \".csv\")\n",
    "            tempPath3 = os.path.join(tempPath1, \"Elec_\" + v + \".pkl\")\n",
    "            newFrame_elec.to_csv(tempPath2)\n",
    "            newFrame_elec.to_pickle(tempPath3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736f5e0b",
   "metadata": {},
   "source": [
    "\n",
    "# Function: readData\n",
    " ### Reads the source folder generated and returns a, b, c as dictionaries.\n",
    " \n",
    "### Note:  -1 is a dummy value (for self-loops and array padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9785cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTDATED \n",
    "# =======================================================\n",
    "# FUNCTION: Reader of pickle files for (a, b) coefficients\n",
    "#   a, b = readDataCSV(\"<Folder Name>\")\n",
    "#\n",
    "# Arguments:\n",
    "#   saveFolderName    (str ) the foldername for the stored pickle files. Default :\"OLS_Data\"\n",
    "#\n",
    "# Returns:\n",
    "#   a [ k ][ i ][ j ] (dict) k is the Vehiecle Type, i is the starting node, and j is the end node\n",
    "#   b [ k ][ i ][ j ] (dict) k is the Vehiecle Type, i is the starting node, and j is the end node\n",
    "# \n",
    "#   Notes:\n",
    "#   - i and j are 1 indexed, for convenience. i = 0 or j = 0, holds garbage values.\n",
    "#   - The name of vehicles, k, needs to be exactly the same as the \n",
    "#     column from the datafile used to generate the pickle files.\n",
    "# =======================================================\n",
    "\n",
    "def readDataPKL (saveFolderName = \"OLS_Data\"):\n",
    "    \n",
    "    # Initialize some folderpath\n",
    "    path = os.path.join(os.getcwd(), saveFolderName)\n",
    "    \n",
    "    # If the folder doesn't exist, print error and return\n",
    "    if not os.path.exists(path):\n",
    "        print(\"Error, Source Folder Doesn't exist\")\n",
    "        return \n",
    "    \n",
    "    TireTypes = [i[9:] for i in os.listdir(path)]\n",
    "    \n",
    "    # Get the number of nodes brute forcedly\n",
    "    filePath = os.path.join(path, 'Tire_cir_' + TireTypes[0])\n",
    "    VehiecleSamplePath = [ fi for fi in os.listdir(filePath) if fi.endswith(\".pkl\") ]\n",
    "    filePath = os.path.join(filePath, VehiecleSamplePath[0])\n",
    "    df = pd.read_pickle(filePath)\n",
    "    numNodes = np.shape(df.iloc[:, 0].values)[0]\n",
    "    \n",
    "    # Initializing return dictionary\n",
    "    a = {}\n",
    "    b = {}\n",
    "    c = {}\n",
    "    \n",
    "    fuelType = ['Fuel','Elec']\n",
    "    \n",
    "    for t in TireTypes:\n",
    "        t_path = os.path.join(path, 'Tire_cir_' + t)\n",
    "        a[t] = {}\n",
    "        b[t] = {}\n",
    "        c[t] = {}\n",
    "        VehiecleTypesPath = [ fi for fi in os.listdir(t_path) if fi.endswith(\".pkl\") ]\n",
    "        VehiecleTypes = [i[5:len(i) - 4] for i in VehiecleTypesPath] # change to use split or something else\n",
    "        VehiecleTypes = list(set(VehiecleTypes))# remove duplicates\n",
    "        \n",
    "        for f in fuelType:\n",
    "            a[t][f] = {}\n",
    "            b[t][f] = {}\n",
    "            c[t][f] = {}\n",
    "            for ind, v in enumerate(VehiecleTypes):\n",
    "                filePath = os.path.join(t_path, f + \"_\" + v + \".pkl\")\n",
    "                if not os.path.exists(filePath):\n",
    "                    a[t][f][v] = np.full((numNodes + 1, numNodes + 1), np.nan)\n",
    "                    b[t][f][v] = np.full((numNodes + 1, numNodes + 1), np.nan)\n",
    "                    c[t][f][v] = np.full((numNodes + 1, numNodes + 1), np.nan)\n",
    "                    continue \n",
    "                df = pd.read_pickle(filePath)\n",
    "\n",
    "                # initialize an empty array to store the days\n",
    "                a[t][f][v] = np.full((numNodes + 1, numNodes + 1), -1, dtype = float)\n",
    "                b[t][f][v] = np.full((numNodes + 1, numNodes + 1), -1, dtype = float)\n",
    "                c[t][f][v] = np.full((numNodes + 1, numNodes + 1), -1, dtype = float)\n",
    "\n",
    "                results = df.to_numpy().transpose()\n",
    "                for i, temp in enumerate(results, 1):\n",
    "                    for j, ab in enumerate(temp, 1):\n",
    "                        if type(ab) == tuple:\n",
    "                            a[t][f][v][i][j], b[t][f][v][i][j], c[t][f][v][i][j] = ab[0], ab[1] , ab[2] \n",
    "                        else:\n",
    "                            a[t][f][v][i][j], b[t][f][v][i][j], c[t][f][v][i][j] = np.nan, np.nan, np.nan\n",
    "\n",
    "    return a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "47e3a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = readDataPKL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0cbf36e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.2455390960503074e-05, 0.2943450392769703)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example lookup\n",
    "t = '0.00427'\n",
    "f = 'Elec' # or 'Fuel'\n",
    "# v = 'class8_conv_2021_daycab_regionalhaul_FU19'\n",
    "# v = 'class8_bev_2021_daycab_regionalhaul_FU19'\n",
    "v = 'class8_bev_2021_low_sleeper_longhaul_FU19'\n",
    "i = 1\n",
    "j = 2\n",
    "\n",
    "a[t][f][v][i][j], b[t][f][v][i][j], c[t][f][v][i][j] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a6ac27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
